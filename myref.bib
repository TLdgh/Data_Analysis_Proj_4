@article{aryal2014improving,
  title={Improving iForest with relative mass},
  author={Aryal, Sunil and Ting, Kai Ming and Wells, Jonathan Robert and Washio, Takashi},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining 2014},
  pages={510--521},
  year={2014},
  organization={Springer}
}

@article{DengDingsheng2020DCAB,
abstract = {Clustering technology has important applications in data mining, pattern recognition, machine learning and other fields. However, with the explosive growth of data, traditional clustering algorithm is more and more difficult to meet the needs of big data analysis. How to improve the traditional clustering algorithm and ensure the quality and efficiency of clustering under the background of big data has become an important research topic of artificial intelligence and big data processing. The density-based clustering algorithm can cluster arbitrarily shaped data sets in the case of unknown data distribution. DBSCAN is a classical density-based clustering algorithm, which is widely used for data clustering analysis due to its simple and efficient characteristics. The purpose of this paper is to study DBSCAN clustering algorithm based on density. This paper first introduces the concept of DBSCAN algorithm, and then carries out performance tests on DBSCAN algorithm in three different data sets. By analyzing the experimental results, it can be concluded that DBSCAN algorithm has higher homogeneity and diversity when it performs personalized clustering on data sets of non-uniform density with broad values and gradually sparse forwards. When the DBSCAN algorithm's neighborhood distance eps is 1000, 26 classes are generated after clustering.},
author = {Deng, Dingsheng},
booktitle = {2020 7th International Forum on Electrical Engineering and Automation (IFEEA)},
isbn = {9781728196275},
keywords = {Algorithm Research ; Big Data ; Clustering algorithms ; Data mining ; DBSCAN Algorithm ; Density Clustering ; Machine learning ; Machine learning algorithms ; Prediction algorithms ; Unsupervised learning},
language = {eng},
pages = {949-953},
publisher = {IEEE},
title = {DBSCAN Clustering Algorithm Based on Density},
year = {2020},
}

@article{YinLifeng2023IoDA,
abstract = {For the shortcomings of an unstable clustering effect and low accuracy caused by the manual setting of the two parameters Eps and MinPts of the DBSCAN (density-based spatial clustering of applications with noise) algorithm, this paper proposes an adaptive determination method for DBSCAN algorithm parameters based on the K-dist graph, noted as X-DBSCAN. The algorithm uses the least squares polynomial curve fitting method to fit the curve in the K-dist graph to generate a list of candidate Eps parameters and uses the mathematical expectation method and noise reduction threshold to generate the corresponding MinPts parameter list. According to the clustering results of each group of parameters in the Eps and MinPts parameter lists, a stable range of cluster number changes is found, and the MinPts and Eps corresponding to the maximum K value in the stable range are selected as the optimal algorithm parameters. The optimality of this parameter was verified using silhouette coefficients. A variety of experiments were designed from multiple angles on the artificial dataset and the UCI real dataset. The experimental results show that the clustering accuracy of X-DBSCAN was 21.83% and 15.52% higher than that of DBSCAN on the artificial and real datasets, respectively. The X-DBSCAN algorithm was also superior to other algorithms through comprehensive evaluation and analysis of various clustering indicators. In addition, experiments on four synthetic Gaussian datasets of different dimensions showed that the average clustering indices of the proposed algorithm were above 0.999. The X-DBSCAN algorithm can select parameters adaptively in combination with the characteristics of the dataset; the clustering effect is better, and clustering process automation is realized.},
author = {Yin, Lifeng and Hu, Hongtao and Li, Kunpeng and Zheng, Guanghai and Qu, Yingwei and Chen, Huayue},
address = {Basel},
copyright = {Copyright 2023 Elsevier B.V., All rights reserved.},
issn = {2079-9292},
journal = {Electronics (Basel)},
keywords = {adaptive parameter ; Algorithms ; Cluster analysis ; Clustering ; Clustering (Computers) ; Curve fitting ; Data mining ; Datasets ; DBSCAN algorithm ; K-dist graph ; Mathematical analysis ; Methods ; Neighborhoods ; Noise reduction ; noise reduction threshold ; Noise threshold ; Optimization ; parameter optimization ; Parameters ; Polynomials},
language = {eng},
number = {15},
pages = {3213-},
publisher = {MDPI AG},
title = {Improvement of DBSCAN Algorithm Based on K-Dist Graph for Adaptive Determining Parameters},
volume = {12},
year = {2023},
}

@article{SmitiAbir2020Acoo,
abstract = {One of the opening steps towards obtaining a reasoned analysis is the detection of outlaying observations. Even if outliers are often considered as a miscalculation or noise, they may bring significant information. For that reason, it is important to spot them prior to modeling and analysis. In this paper, we will present a structured and comprehensive review of the research on outlier detection. We have clustered existing methods into different categories based on the underlying approach adopted by each technique. In addition, for each category, we provide a discussion on the advantages and disadvantages of each method. Our paperâ€™s purpose is to assist the novice researcher, to produce clear ideas and to facilitate a better understanding of the different directions in which research has been done on this topic.},
author = {Smiti, Abir},
copyright = {2020 Elsevier Inc.},
issn = {1574-0137},
journal = {Computer science review},
keywords = {Machine learning ; Noise ; Outlier ; Outlier detection},
language = {eng},
pages = {100306-},
publisher = {Elsevier Inc},
title = {A critical overview of outlier detection methods},
volume = {38},
year = {2020},
}